{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Conditional Random Fields\n",
    "\n",
    "Let's see how well Dirko Coetsee's `pyhacrf` package does..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "from pyhacrf import StringPairFeatureExtractor, Hacrf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "with open(\"gam_pos.p\", \"rb\") as f:\n",
    "    gam_pos = p.load(f)\n",
    "with open(\"kur_pos.p\", \"rb\") as f:\n",
    "    kur_pos = p.load(f)\n",
    "with open(\"gam_neg.p\", \"rb\") as f:\n",
    "    gam_neg = p.load(f)\n",
    "with open(\"kur_neg.p\", \"rb\") as f:\n",
    "    kur_neg = p.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyhacrf` requires that the training data come in the form of two lists:\n",
    "\n",
    "* x = a list of tuples, each of which contains two strings\n",
    "* y = a list of strings, indicating whether the tuples are a 'match' or 'non-match'\n",
    "\n",
    "To begin with, I reserve the Gamilaraay data as test data, to see if a model trained on one aboriginal language can do well on another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep five random negative matches for each anchor.\n",
    "def keep_n(df, n = 5):\n",
    "    \"\"\"\n",
    "    A little helper function that keeps n randomly selected rows from a data frame.\n",
    "    Can be used with DataFrame.groupby.apply() to keep n rows from arbitarily defined\n",
    "    groups of a data frame.\n",
    "    \n",
    "    params:\n",
    "        df: a Pandas DataFrame\n",
    "        n: the number of rows to keep\n",
    "    \n",
    "    returns:\n",
    "        selection: a shorter DataFrame with the required number of rows\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reset n if too large for this DataFrame:\n",
    "    if n > len(df):\n",
    "        n = len(df)\n",
    "    \n",
    "    # Randomly choose which rows to keep\n",
    "    rows_to_keep = np.random.choice(range(len(df)), n, replace = False)\n",
    "    \n",
    "    # Keep them\n",
    "    selection = df.iloc[rows_to_keep, :]\n",
    "    \n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(3), 1, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training data\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# Just get juiciest training examples.\n",
    "gam_pos = gam_pos[\n",
    "    (gam_pos.pos_dist > 0.4) & # more than .4 apart in normalised Levenshtein (to avoid being too similar)\n",
    "    (gam_pos.pos_dist < 0.5) & # no more than .5 apart (to avoid false positives)\n",
    "    (gam_pos.anchor.str.len() < 10) # no more than 10 characters long (to avoid junk entries)\n",
    "]\n",
    "gam_pos = gam_pos.sample(frac = 1).reset_index(drop = True) # Shuffle training examples \n",
    "pos_iter = gam_pos[['anchor','positive']].itertuples(index = False, name = None) # Create iterator\n",
    "\n",
    "x += list(pos_iter) # Add to x list\n",
    "y += ['match' for i in range(len(gam_pos))] # Generate appropriate y labels\n",
    "\n",
    "# Get the juiciest negative examples\n",
    "gam_neg = gam_neg[\n",
    "    (gam_neg.neg_dist > 0.4) & # more than .4 apart to ensure no false negatives\n",
    "    (gam_neg.neg_dist < 0.44) # no more than .44 apart to ensure that they are no too dissimilar\n",
    "]\n",
    "gam_neg = gam_neg.groupby('anchor').apply(keep_n, n = 1) # just keep one random example per anchor word\n",
    "gam_neg = gam_neg.sample(frac = 1).reset_index(drop = True) # Shuffle training examples \n",
    "neg_iter = gam_neg[['anchor','neg_match']].itertuples(index = False, name = None)\n",
    "x += list(neg_iter) # Add to x list\n",
    "y += ['non-match' for i in range(len(gam_neg))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 881 positive examples and 947 negative ones.\n"
     ]
    }
   ],
   "source": [
    "# Applying those conditions has created a roughly equal number of positive and negative training examples:\n",
    "print(f\"There are {len(gam_pos)} positive examples and {len(gam_neg)} negative ones.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Train the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create charset\n",
    "# Join all the tuples into one list\n",
    "one_list = [''.join(list(x)) for x in x]\n",
    "# Put in lower case\n",
    "lowered = [x.lower() for x in one_list]\n",
    "# Join into single string and set\n",
    "charset = set(''.join(lowered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 1463\n",
      "y_train: 1463\n",
      "x_test: 365\n",
      "y_test: 365\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "feature_extractor = StringPairFeatureExtractor(match=True, transition=True, charset = charset)\n",
    "x_extracted = feature_extractor.fit_transform(x)\n",
    "\n",
    "# Train-test split\n",
    "# Data has already been shuffled\n",
    "pos_split = int(np.ceil(len(gam_pos) * 0.8)) # Where is the 80th percentile in the positive examples?\n",
    "pos_end = len(gam_pos)\n",
    "neg_split = int(np.ceil(len(gam_neg) * 0.8)) + len(gam_pos) # Where is the 80th percentile in the negative ones?\n",
    "neg_end = len(x)\n",
    "\n",
    "# Take equal portions of the positive and negative examples\n",
    "x_train = x_extracted[0:pos_split] + x_extracted[pos_end:neg_split]\n",
    "y_train = y[0:pos_split] + y[pos_end:neg_split]\n",
    "\n",
    "x_test = x_extracted[pos_split:pos_end] + x_extracted[neg_split:neg_end]\n",
    "y_test = y[pos_split:pos_end] + y[neg_split:neg_end]\n",
    "\n",
    "# Dimensions\n",
    "print(f\"x_train: {len(x_train)}\\ny_train: {len(y_train)}\\nx_test: {len(x_test)}\\ny_test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each training example consists of a rank-3 tensor. The rows represent the first string in the training pair, the columns the second string, and in each position is a ~1800-dimensional vector representing which characters have been switched for which in each place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7, 1683)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = Hacrf(l2_regularization=1.0)\n",
    "model.fit(x_train, y_train, verbosity = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
